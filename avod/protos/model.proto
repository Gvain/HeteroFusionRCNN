package avod.protos;

import "avod/protos/mini_batch.proto";
import "avod/protos/layers.proto";

// Message for configuring the DetectionModel.
message ModelConfig {

    // Model name used to run either RPN or AVOD
    optional string model_name = 1 [default = 'avod_model'];
    // if alteraning-training, for RpnModle, [1,3] is valid, for AvodModel, [2,4] is valid
    // default 0 is for joint-training
    optional int32 alternating_training_step = 14 [default = 0];

    // Checkpoint name
    optional string checkpoint_name = 2 [default = 'detection_model'];

    optional PathsConfig paths_config = 3;
    required InputConfig input_config = 4;
    required RpnConfig rpn_config = 5;
    required AvodConfig avod_config = 6;

    // Label smoothing epsilon
    required float label_smoothing_epsilon = 7;

    // Global path drop (p_keep_img, p_keep_bev)
    // To disable path drop, set both to 1.0
    repeated float path_drop_probabilities = 9;

    // To keep all the samples including the ones without anchor-info
    // i.e. labels during training
    required bool train_on_all_samples = 10;

    // To keep all the samples including the ones without anchor-info
    // i.e. labels during validation
    required bool eval_all_samples = 11;

    // Layer configurations
    required LayersConfig layers_config = 12;

    // Loss configurations
    required LossConfig loss_config = 13;
}

message PathsConfig {
    // Checkpoint dir
    optional string checkpoint_dir = 1;

    // Log dir (no underscore to match tensorboard)
    optional string logdir = 2;

    // Directory to save predictions
    optional string pred_dir = 3;
}

message InputConfig {
    // PC dimensions
    optional int32 pc_sample_pts = 2 [default = 16384];
    optional int32 pc_data_dim = 3 [default = 3];

    optional float pc_sample_pts_variance = 6 [default = 0.125];
    optional float pc_sample_pts_clip = 7 [default = 0.25];
    // Image dimensions
    //optional int32 img_dims_h = 4 [default = 480];
    //optional int32 img_dims_w = 5 [default = 1590];
    //optional int32 img_depth = 6 [default = 3];
}

message RpnConfig {
    // RPN proposal ROI crop size
    required int32 rpn_proposal_roi_crop_size = 1;

    // RPN proposal ROI fusion method, one of ['mean', 'concat']
    required string rpn_fusion_method = 2;

    // RPN Non-max suppression boxes during training
    required int32 rpn_train_nms_size = 3;

    // RPN NMS IoU threshold during training
    required float rpn_train_nms_iou_thresh = 4;
    
    // RPN Non-max suppression boxes during testing
    required int32 rpn_test_nms_size = 5;

    // RPN NMS IoU threshold during testing
    required float rpn_test_nms_iou_thresh = 6;

    required float rpn_xz_search_range = 7;
    required float rpn_xz_bin_len = 8;
    // in fraction of PI
    required float rpn_theta_search_range = 9;
    required int32 rpn_theta_bin_num = 10;

    // Whether to use intensity feature
    required bool rpn_use_intensity_feature = 11;
}

message AvodConfig {
    // AVOD Proposal ROI crop size
    required int32 avod_proposal_roi_crop_size = 1;

    // Positive selection, one of ['corr_cls', 'not_bkg']
    required string avod_positive_selection = 3;

    // AVOD Non-max suppression boxes
    required int32 avod_nms_size = 4;

    // AVOD NMS IoU threshold
    required float avod_nms_iou_thresh = 5;

    // AVOD bounding box representation, one of ['box_3d', 'box_8c']
    required string avod_box_representation = 6;
    
    required float avod_xz_search_range = 7;
    required float avod_xz_bin_len = 8;
    // in fraction of PI
    required float avod_theta_search_range = 9;
    // in units of degree
    required float avod_theta_bin_len = 10;

    required float avod_pooling_context_length = 11; 
    
    optional MiniBatchConfig mini_batch_config = 12;

    // Whether to use intensity feature along with mask and distance to sensor features
    required bool avod_use_intensity_feature = 13;
}

message LossConfig {
    // RPN/AVOD Regression loss weight
    required float reg_loss_weight = 1;

    // AVOD angle vector loss weight
    required float ang_loss_weight = 2;

    // RPN/AVOD Classification loss weight
    required float cls_loss_weight = 3;
    
    // RPN segmentation loss weight
    optional float seg_loss_weight = 4 [default = 1.0];
}

